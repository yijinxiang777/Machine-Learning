---
title: "Glossary"
author: "Yijin Xaing"
output:
  html_document:
    toc: yes
    toc_float: yes
    toc_depth: 3
  html_notebook:
  #   toc: yes
  #  toc_float: yes
bibliography: bibliography.bibtex
minutes: 300
layout: page
---

Definitions and explanations of terms in the book [THE HUNDRED-PAGE MACHINE LEARNING BOOK](http://themlbook.com) written by Andriy Burkov  

### supervised learning   
Regressing an outcome (referred to as labels) regressed against covariates (or eatures).  
The goal is to use data to produce a model that takes features as input and outputs information about label.  

**Methods**: SVM

**Case study**     
  

### dataset  
A collection of examples.    

### labeled examples
A dataset contains both outcome (label) and covraites (features), from which models learn, in supervised training .
$\{(x_{i},y_{i})\}_{i=1}^{N}$  

### feature vector  
A vector **x** in which each dimension $\mathcal{j} = 1, \cdots , D$ contains a value $x^{(j)}$. We have a dataset of infant development, including weight, height, and head circumference. Assuming each example **x** in the dataset represents a patient, $x^{(1)}$ can denote the first feature (exposure), which is weight.   


### feature  
We also call it exposure and denote it as  $x^{(j)}$. The feature at position j in all the feature vectors always contains the same kind of information in one dataset. It means that if the second feature of the first patients $x_{1}^{(2)}$ in the dataset is weight, then the second feature of any patient $x_{k}^{(2)}$ will be weight.

### label  
We also call it outcome. labeled examples can be denoted as $\left \{(x_{i}, y_{i}) \right \}_{i=1}^{N}$. $(x_{1}, y_{1})$ represents the data for the first individual and every $x_{i}$ among N is called a feature vector.   

### class    

A set of values for a label(outcome) with finite categories. The label $y_{i}$ can be either an element belonging to a finite set of classes $\left \{1,2,\cdots,C \right \}$, or a real number, or a more complex structure, like a vector, or a matrix. A set with two values can denote the class of any dichotomous outcome, such as {Yes, No}, {1, 0}.  


### unsupurvised learning
An analysis of unlabeled (i.e., no outcome) data.   
A collection of unlabeled variables is used to create a model that solves "practical problem" such as cluster detection, dimension reduction, or outlier detection.  

**Case study**  
Plan to put the example of Kim [@RN1]

### unlabeled example
A dataset with only features (exposures) but no label (outcome), for example, a dataset of patients' features (e.g., susceptibility to specific drugs), aiming to gain different subgroups. We denote it as $\{(x_{i})\}_{i=1}^{N}$.    

### model
### clustering
### dimensionality reduction
### outlier detection
### semi-supervised learning  
It is the same as supervised learning, except that there are more feature vectors (covariates) than there are labeled outputs (outcomes). The rationale is to improve performance of supervised learning model using more feature vectors. The goal is typically to develop an algorithm that predicts outcomes or classifies observations with both missing and observed outcome values.    

We can also call it regression with missing data - to train models on complete data, and use these models to predict outcomes for observations without outcomes.  

**Case study**[@RN3]  
*Background* Fetal weight and continuum of fetal growth have been identified as indicators for perinatal and childhood outcomes. However, most of the attempts to proxy the measurement were based on population referents and standards. 
*Methods* Fetal weight predictions for each gestational week per person were compared to actual fetal weight measurements obtained using standard ultrasound protocols. $\gamma(Y|X=x)=h(x)$   


### reinforcement learning
Machine lives in an environment and is capable of perceiving state. Machine executes actions that yield different rewards and move machine into another state. Goal of reinforcement learning is for machine to learn a "policy" - a function that takes feaeture vector as input (state) and outputs optimal action (i.e., maximizing expected average reward).  

**Case study** 
Zhang and Bareinboim (2020)[@RN2]

### bag of words
### support vector machine (SVM)
$y=sign(\boldsymbol{wx}-b)$    

- sign() operator is a function that returns -1 if the sign of the argument in the parentheses is negative, and +1 otherwise.  

- $\boldsymbol{wx}$ is a feature vector and parameters, which can be rewritten as the sum of products between parameters and variables.   

- $b$ is an intercept parameter  

- Objective of the fitting procedure: finding a set of values for $\boldsymbol{\bar{w}}$ and $\bar{b}$ that make the output from $sign(\boldsymbol{wx}-b)$ as close to the oberved values of y as possible.  

### learning algorithm

### decision boundary
The boundary separating the examples of different classes   

### parameters
A real-valued vector w of the same dimensionality as our input feature vector $X$ $(WX)$: $(\omega)^{(1)}(x)^{(1)} + (\omega)^{(2)}(x)^{(2)}+ (\omega)^{(3)}(x)^{(3)}+...+(\omega)^{(D)}(x)^{(D)}$  
$D$ is the number of dimensions of the feature vector $X$.  

### margin

### generalization
How well the model will clssify new examples in the future.  

### statistical model

### training


### kernels

### outliers

### accuracy
The ratio of examples whose labels (outcomes) are predicted correctly.
$$\frac{true \ positive + true \ negative}{all  \ cases}$$   


## Notation     



### scalar  
Simple numerical value, like 15 or -3.25. Variables or constants that take scalar values are denoted by an italic letter, like *x* or *a*.

### vector
An ordered list of scalar values. A vector are usually denoted as a bold character, for example, **x** or **w**. It can be visualized as arrows that point to some directions as well as points in a multi-dimensional space.   


### matrix  
A rectangular array of numbers arranged in rows and column. A matrix is usually denoted with bold capital letters, such as **A** or **W**.

### dimension

### set 
An unordered collection of unique elements. A set is often denoted as a calligraphic capital character, for example, $\mathcal{S}$.    

- intersection: obtaining a set with the common elements. $\mathcal{S}_{1}\bigcap\mathcal{S}_{2}$  

- union: obtaining a set with all unique elements. $\mathcal{S}_{1}\bigcup\mathcal{S}_{2}$  

### Capital Sigma Notation  
The summation over a collection $\mathcal{X} = \left \{x_{1}, x_{2},\cdots,x_{n-1}, x_{n}\right \}$ or over the attributes of a vector $\mathbf{X}=\left [x^{(1)}, x^{(2)},\cdots,x^{(m-1)}, x^{(m)} \right ]$ 

We denote it as: 
 $\sum_{i=1}^{n}x_{i} \overset{def}{=} x_{1}+x_{2}+\cdots +x_{n-1}+x_{n}$ or
 $\sum_{i=1}^{n}x^{i} \overset{def}{=} x^{(1)}+  x^{(2)}+ \cdots+ x^{(m-1)} + x^{(m)}$

### Capital Pi Notation   

## Reference
